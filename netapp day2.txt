
1. IPspace
- There are 2 existing IPspace : Cluster (InterConnect) & Default (all SVMs)
- Do we need to create additional IPspace?
  --> there is conflicting IP subnets / range
  --> multi-tenancy / you are service provider / telco

2. Broadcast Domain
- There are 2 existing BD : Cluster & Default
- isolate ur physical ports

3. Failover Group
- There are 2 existing FG : Cluster & Default
- handle NAS LIF failover
- when failover, which targets ports that you can fail

4. Failover Policy
- 4 policies
- handle NAS LIF failover
- apply to NAS LIF
  network interface modify

5. Subnet
- like DHCP - release IP to NAS LIFs (created)
- there is no predefined subnet

SAN LIF (FC, FCoE, iSCSI, NVMEoFC, NVMEoTCP)
- mpio (netapp utilities)


First scenario: when active link and failover link is different speed
- first port (10G)
failover to second port (1G)
automatic failover 

Second scenerio: same speed, better not (default)
manual failover


network interface modify -lif <lif-name> -failover auto/manual

tea break

11am

SyncMirror 
- RAID 10 (1+0)

RAID-4 : Stripe set with dedicated parity
- min 3
RAID-DP: Stripe set with double dedicated parity  
- min 5
RAID-TEC : v9.3 
- afford 3 simultaneous disks failure within raid group
- min 7
vs
RAID-5 : Stripe set with distributed parity
RAID-6 : Stripe set with double distributed parity
RAID-10:SyncMirror


Scenario 1: 
- Put all 100 disks into 1 aggregate with 1 raid group
- 99 data disk + 1 parity

Scenario 2: 
- Put all 100 disks into 1 aggregate with multiple raid group
- 33 raid groups = 67 data disks + 33 parity disks

<=8.3
12 disks goto node1
12 disks goto node2

12 data disks = 50% usable capacity

>v9 Root-Data ADP
18 data disks = 75%

>v9 Root-Data-data ADP
21 data disks = 87.5%

FlashCache
- 1T/2T
- PCIe slots
- card
- all volumes / all type of applications

FlashPool
- HDD + SSD
- multi-tier disks

FabricPool
- SSD (performance-tier) + cloud (capacity-tier)

FlexVol
- logical from SVM
- physical from aggregate (node)
- min 20MB (SVM root volume) - max size 100TB
- 20000 FlexVol / cluster

system/node root volume
- every controller / node
- ontap, configuration, logs
- size 1.5-2.2GB 

FlexGroup
- Max to 20PB 
- can span across multiple aggregate
- technically, behind 200 FlexVol

FlexCache
- cache across cluster/site
- speed up performance over slow WAN

FlexClone

Max 
- / cluster
- FlexVol

Volume Move
- between aggregate/node
- non-disruptive
- physical movement

Volume rehost
- between SVM (virtual/logical)
- disruptive
- v9.3

SVM1 --> SVM2
- routing table
- ipspace/broadcast domain//language/license
- LIF: IP

LUN movement
- file within volume
- logical / LUN ID
- between volume (different language, thin/thick /compressed, snapshot policies )
- within same SVM

github.com/jasonwcc/learntonetapp














]





